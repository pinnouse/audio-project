{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Parsing and Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = os.path.join(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('english\\\\Durian',\n",
       " [],\n",
       " ['aligned.swc',\n",
       "  'audio.ogg',\n",
       "  'audiometa.txt',\n",
       "  'info.json',\n",
       "  'wiki.html',\n",
       "  'wiki.txt',\n",
       "  'wiki.xml'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(os.walk(os.path.join(DATA_DIR, 'Durian')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PronunciationTiming(object):\n",
    "\n",
    "    def __init__(self, word: str, start: int, end: int) -> None:\n",
    "        self.word = word\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "class SWC(object):\n",
    "\n",
    "    def __init__(self, swc_path: str) -> None:\n",
    "        self.tree = ET.parse(swc_path)\n",
    "        self.timings = []\n",
    "\n",
    "    def get_timings(self) -> List[PronunciationTiming]:\n",
    "        if len(self.timings) > 0:\n",
    "            return self.timings\n",
    "        # https://www.geeksforgeeks.org/xml-parsing-python/\n",
    "        root = self.tree.getroot()\n",
    "        doc = root.find('d')\n",
    "\n",
    "        for p in doc.findall('p'):\n",
    "            for s in p.findall('s'):\n",
    "                for t in s.findall('t'):\n",
    "                    for n in t.findall('n'):\n",
    "                        attribs = n.attrib\n",
    "                        if 'pronunciation' not in attribs \\\n",
    "                            or 'start' not in attribs or 'end' not in attribs:\n",
    "                            continue\n",
    "                        word = attribs['pronunciation'].lower()\n",
    "                        self.timings.append(PronunciationTiming(\n",
    "                            word,\n",
    "                            int(attribs['start']),\n",
    "                            int(attribs['end'])))\n",
    "        return self.timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "def split_clip(audio: AudioSegment, swc: SWC\n",
    "               ) -> Tuple[List[str], List[AudioSegment]]:\n",
    "    words = []\n",
    "    clips = []\n",
    "    for p in swc.get_timings():\n",
    "        words.append(p.word)\n",
    "        clip = audio[p.start:p.end]\n",
    "        # https://github.com/jiaaro/pydub/blob/master/API.markdown#audiosegmentget_array_of_samples\n",
    "        # clip = audio[p.start:p.end].get_array_of_samples()\n",
    "        # fp_arr = np.array(clip).T.astype(np.float32)\n",
    "        # fp_arr /= np.iinfo(clip.typecode).max\n",
    "        clips.append(clip)\n",
    "    return words, clips\n",
    "\n",
    "# audio = AudioSegment.from_ogg('english/Durian/audio.ogg')\n",
    "# print(audio.channels, audio.frame_rate)\n",
    "# swc = SWC('english/Durian/aligned.swc')\n",
    "# split_clip(audio, swc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "class PronunciationClip(object):\n",
    "    def __init__(self, word: str, audio: AudioSegment) -> None:\n",
    "        self.word = word\n",
    "        self.audio = audio\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"PronunciationClip({repr(self.word)}, {repr(self.audio)})\"\n",
    "\n",
    "def load_utterances(limit: Optional[int] = 5000, vocab: List[str] = None\n",
    "                    ) -> List[PronunciationClip]:\n",
    "    clips = []\n",
    "\n",
    "    for dir in os.listdir(DATA_DIR):\n",
    "        path = os.path.join(DATA_DIR, dir)\n",
    "        if not os.path.isdir(path):\n",
    "            continue\n",
    "        files = os.listdir(path)\n",
    "        if 'audio.ogg' not in files or 'aligned.swc' not in files:\n",
    "            continue\n",
    "        try:\n",
    "            audio = AudioSegment.from_ogg(os.path.join(path, 'audio.ogg'))\n",
    "        except:  # noqa: E722\n",
    "            print(f'Failed to decode file: {os.path.join(path, \"audio.ogg\")}')\n",
    "            continue\n",
    "        swc = SWC(os.path.join(path, 'aligned.swc'))\n",
    "        words, pcms = split_clip(audio, swc)\n",
    "        for w, c in zip(words, pcms):\n",
    "            # skip words less than 4 chars long or not in vocab\n",
    "            if len(w) < 4 \\\n",
    "                or vocab is not None and w not in vocab:\n",
    "                continue\n",
    "            clips.append(PronunciationClip(w, c))\n",
    "\n",
    "        if limit is not None and len(clips) > limit:\n",
    "            break\n",
    "    return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# clips = load_utterances(None) # 50 minutes to load 100,000 clips\n",
    "# print(len(clips))\n",
    "# clips[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifically Audio Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise_playlist(path: os.PathLike, limit: int = 0) -> List[AudioSegment]:\n",
    "    clips = []\n",
    "    for f in os.listdir(path):\n",
    "        if not f.endswith('wav'):\n",
    "            continue\n",
    "        file_path = os.path.join(path, f)\n",
    "        clips.append(AudioSegment.from_file(file_path))\n",
    "        if limit > 0 and len(clips) > limit:\n",
    "            break\n",
    "    return clips\n",
    "\n",
    "\n",
    "# music_clips = make_noise_playlist(os.path.join('audio', 'music'), 200)\n",
    "# outdoor_clips = make_noise_playlist(os.path.join('audio', 'outside_rural'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nwong\\Documents\\nick-repo\\.conda\\Lib\\site-packages\\pycochleagram-0.1-py3.11.egg\\pycochleagram\\erbfilter.py:8: RuntimeWarning: pycochleagram using non-interactive Agg matplotlib backend\n",
      "  from pycochleagram import utils\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/mcdermottLab/pycochleagram\n",
    "import pycochleagram.cochleagram as cgram\n",
    "from scipy import ndimage\n",
    "\n",
    "N_FILTERS = 50\n",
    "LO_LIM = 30\n",
    "HI_LIM = 7860\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "def gen_clip(audio: AudioSegment, duration: int = 2000) -> AudioSegment:\n",
    "    clip = AudioSegment.silent(duration=duration, frame_rate=SAMPLE_RATE)\n",
    "    audio_duration = len(audio)\n",
    "    offset = max(0, duration / 2 - (audio_duration / 2))\n",
    "    return clip.overlay(audio, offset)\n",
    "\n",
    "def audio_to_cgram(audio: AudioSegment) -> np.array:\n",
    "    # TODO: find audio input type for cochleagram (8-bit integer PCM?)\n",
    "    arr = np.array(audio.get_array_of_samples())\n",
    "    return cgram.human_cochleagram(arr, audio.frame_rate or SAMPLE_RATE,\n",
    "                                   N_FILTERS, LO_LIM, HI_LIM, 4, downsample=200)\n",
    "\n",
    "def aa_cgram(cochleagram: np.ndarray, size: int = 256) -> np.ndarray:\n",
    "    f, t = cochleagram.shape\n",
    "    kx = size / f\n",
    "    ky = size / t\n",
    "    return ndimage.zoom(cochleagram, (kx, ky))\n",
    "\n",
    "# a = gen_clip(clips[0].audio)\n",
    "# c = audio_to_cgram(a)\n",
    "# aa = aa_cgram(c)\n",
    "# c.shape, aa.shape # 211x400, 256x256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import array\n",
    "\n",
    "\n",
    "def overlay_noise(snr: float, signal: AudioSegment, noise: AudioSegment\n",
    "                  ) -> AudioSegment:\n",
    "    # signal = signal.normalize()\n",
    "    # noise = noise.normalize()\n",
    "    # gain = snr - signal.dBFS + noise.dBFS\n",
    "    # scaled_noise = noise.apply_gain(-gain)\n",
    "    # print(np.min(s), np.max(s))\n",
    "    # print(np.min(ss), np.max(ss))\n",
    "    signal_rms = signal.rms\n",
    "    noise_rms = noise.rms\n",
    "    scaling_factor = signal_rms / noise_rms * 10**(-snr/20)\n",
    "    noise_np = np.array(noise.set_channels(1).get_array_of_samples())\n",
    "    noise_samples = noise_np * scaling_factor\n",
    "    # new_noise_rms = np.sqrt(np.mean(np.square(noise_samples)))\n",
    "    # new_snr = (signal_rms / new_noise_rms) ** 2\n",
    "    noise_array = array.array(signal.array_type, np.round(noise_samples).astype(np.int32))\n",
    "    scaled_noise = noise._spawn(noise_array)\n",
    "    return signal.overlay(scaled_noise, loop=True)\n",
    "\n",
    "# noise = AudioSegment.from_file('audio/outside_rural/snipped119_start_240_end_250.wav')\n",
    "# overlay_noise(2.0, gen_clip(clips[0].audio), noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count word frequencies to consider which data points we will keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x17d81714260>,\n",
       "  <matplotlib.lines.Line2D at 0x17d81717ec0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x17d81717c80>,\n",
       "  <matplotlib.lines.Line2D at 0x17d81717980>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x17d81714560>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x17d817176b0>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x17d81717440>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAs2UlEQVR4nO3df3RU9Z3/8ddMfgnJBOIPJgEFg0GpBukmYBLrGCFSZI2VWV3FetTualsspx7PguxGd/eI31OTLWdxdyt6TherrSK7blpC1x8gUBNSmqWCRcOqrJMA9YTJRBJCQhLJj/l8/7AZM5LSIJPMvTfPxznvc2bu553MJzmH3Bf33s+9LklGAAAANuKO9wQAAADOFgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYDgEGAADYTmK8JzCapk6dqs7OznhPAwAAnAWPx6OjR4+escexAWbq1KlqamqK9zQAAMCXMG3atDOGGMcGmMEjL9OmTeMoDAAANuHxeNTU1PQn992ODTCDOjs7CTAAADjMWV/E6/P59Mtf/lJNTU0yxujWW289rWfNmjU6evSouru7tX37duXk5ESNZ2Rk6KWXXtKJEyd0/PhxbdiwQampqVE9c+bM0a5du9TT06Pf//73euSRR852qgAAwKHOOsCkpqbq3Xff1YoVK4YdX716tR566CEtX75cBQUF6urq0rZt25SSkhLp2bhxo6666iotWrRIpaWluv766/XjH/84Mu7xePTmm2/qyJEjys/P1yOPPKLHH39c3/72t7/EjwgAAJzIfNkyxphbb701atvRo0fNypUrI+/T09NNT0+PufPOO40kM3v2bGOMMfn5+ZGexYsXm4GBAZOVlWUkmeXLl5vW1laTlJQU6SkvLzcffPDBiOfm8XiMMcZ4PJ4v/fNRFEVRFDW2NdL9d0zvA5Odna2srCzt2LEjsq2jo0N79uxRUVGRJKmoqEjHjx/Xvn37Ij07duxQOBxWQUFBpGfXrl3q6+uL9Gzbtk2zZ8/W5MmTh/3s5ORkeTyeqAIAAM4U0wCTmZkpSQqFQlHbQ6FQZCwzM1MtLS1R4wMDA2pra4vqGe57DP2MLyorK1NHR0ekWEINAIBzOeZOvOXl5UpPT4/UtGnT4j0lAAAwSmIaYJqbmyVJXq83arvX642MNTc3a8qUKVHjCQkJOv/886N6hvseQz/ji3p7eyNLplk6DQCAs8U0wBw6dEjBYFAlJSWRbR6PRwUFBaqrq5Mk1dXVKSMjQ3l5eZGehQsXyu12a8+ePZGe66+/XomJn9+mZtGiRfrwww/V3t4eyykDAACbOqurg1NTU83cuXPN3LlzjTHGPPzww2bu3LnmkksuMZLM6tWrTVtbm7nllltMbm6u2bx5s2loaDApKSmR7/H666+bffv2mfnz55trr73WHDx40GzcuDEynp6eboLBoPnpT39qrrzySnPHHXeYkydPmm9/+9sxv4qZoih7ldvtNsXFxWbZsmWmuLjYuN3uuM+JoqjY1Vnsv8/uGxcXF5vhPP/885GeNWvWmGAwaHp6esz27dvNrFmzor5HRkaG2bhxo+no6DDt7e3mueeeM6mpqVE9c+bMMbt27TI9PT3m448/NqtXrx6tXwBFUTYpv99vGhsbo/72NDY2Gr/fH/e5URQVmxq1AGOXIsBQlLPK7/ebgYEBs2XLFlNQUGBSU1NNQUGB2bJlixkYGCDEUJRDaqT7b9cfXjiOx+NRR0eH0tPTuaAXsDm3261AIKD6+notXbpUxnz+Z8vlcqmqqkq5ubmaNWuWwuFwHGcK4FyNdP/tmGXUAJzL5/MpOztbTz75ZFR4kSRjjMrLyzVz5kz5fL44zRDAWCPAALC8rKwsSdKBAweGHR/cPtgHwPkIMAAsLxgMSpJyc3OHHR/cPtgHwPkIMAAsr7a2VocOHdKjjz4ql8sVNeZyuVRWVqbGxkbV1tbGaYYAxhoBBoDlhcNhrVy5UqWlpaqqqlJhYaHS0tJUWFioqqoqlZaWatWqVVzAC4wzcV8yNRrFMmqKcl4Ndx+YhoYGllBTlIOKZdQsowYcye12y+fzKSsrS8FgULW1tRx5ARxkpPvvxD86AgAWFA6HVVNTE+9pAIgzroEBAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2Q4ABAAC2kxjvCQDA2XC73fL5fMrKylIwGFRtba3C4XC8pwVgjHEEBoBt+P1+BQIBVVdXa9OmTaqurlYgEJDf74/31ACMMQIMAFvw+/2qrKxUfX29CgsLlZaWpsLCQtXX16uyspIQA4wzLkkm3pMYDR6PRx0dHUpPT1dnZ2e8pwPgHLjdbgUCAdXX12vp0qUy5vM/Wy6XS1VVVcrNzdWsWbM4nQTY3Ej33xyBAWB5Pp9P2dnZevLJJ6PCiyQZY1ReXq6ZM2fK5/PFaYYAxhoBBoDlZWVlSZIOHDgw7Pjg9sE+AM5HgAFgecFgUJKUm5s77Pjg9sE+AM5HgAFgebW1tTp06JAeffRRuVyuqDGXy6WysjI1NjaqtrY2TjMEMNYIMAAsLxwOa+XKlSotLVVVVVXUKqSqqiqVlpZq1apVXMALjDPGieXxeIwxxng8nrjPhaKo2JTf7zeNjY1mqIaGBuP3++M+N4qiYlMj3X+zjBqArXAnXsDZRrr/5lECAGwlHA6rpqYm3tMAEGdcAwMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGwn5gHG7XbriSeeUGNjo7q7uxUIBPT3f//3p/WtWbNGR48eVXd3t7Zv366cnJyo8YyMDL300ks6ceKEjh8/rg0bNig1NTXW0wUAADYV0xvQlJWVmU8++cT8+Z//uZkxY4a57bbbTEdHh/n+978f6Vm9erU5fvy4+cY3vmHmzJljqqqqTENDg0lJSYn0vP766+Z3v/udueaaa8zXvvY183//939m48aNMb8RDkVRFEVR1qmz2H/H9oP/+7//22zYsCFqW2VlpXnxxRcj748ePWpWrlwZeZ+enm56enrMnXfeaSSZ2bNnG2OMyc/Pj/QsXrzYDAwMmKysrFj/AiiKoiiKskiNdP8d81NIv/nNb1RSUqJZs2ZJkq6++mpdd911euONNyRJ2dnZysrK0o4dOyJf09HRoT179qioqEiSVFRUpOPHj2vfvn2Rnh07digcDqugoGDYz01OTpbH44kqAADgTDG/E29FRYXS09P14YcfamBgQAkJCXrsscf08ssvS5IyMzMlSaFQKOrrQqFQZCwzM1MtLS1R4wMDA2pra4v0fFFZWZkef/zxGP80AADAimJ+BOaOO+7Q3XffrW9+85vKy8vTfffdp1WrVunee++N9UdFKS8vV3p6eqSmTZs2qp8HAADiJ+ZHYNauXauKigr953/+pyTpwIEDmjFjhsrKyvSzn/1Mzc3NkiSv1xt5Pfh+//79kqTm5mZNmTIl6vsmJCTo/PPPj/qaoXp7e9Xb2xvrHwcAAFhQzI/ATJw48bQnww4MDMjt/uyjDh06pGAwqJKSksi4x+NRQUGB6urqJEl1dXXKyMhQXl5epGfhwoVyu93as2dPrKcMAABsKKZXDz///PPm448/jiyjXrp0qWlpaTEVFRWRntWrV5u2tjZzyy23mNzcXLN58+Zhl1Hv27fPzJ8/31x77bXm4MGDLKOmKIqiKIdX3JZRp6WlmaeeesocPnzYdHd3m0AgYP7f//t/JikpKapvzZo1JhgMmp6eHrN9+3Yza9asqPGMjAyzceNG09HRYdrb281zzz1nUlNTR+MXQFEURVGURWqk+2/XH144jsfjUUdHh9LT09XZ2Rnv6QCIEbfbLZ/Pp6ysLAWDQdXW1p522hqAfY10/82zkADYht/vVyAQUHV1tTZt2qTq6moFAgH5/f54Tw3AGCPAALAFv9+vyspK1dfXq7CwUGlpaSosLFR9fb0qKysJMcA4wykkAJbndrsVCARUX1+vpUuXypjP/2y5XC5VVVUpNzdXs2bN4nQSYHOcQgLgGD6fT9nZ2XryySejwoskGWNUXl6umTNnyufzxWmGAMYaAQaA5WVlZUn67MaYwxncPtgHwPkIMAAsLxgMSpJyc3OHHR/cPtgHwPkIMAAsr7a2VocOHdKjjz4ql8sVNeZyuVRWVqbGxkbV1tbGaYYAxhoBBoDlhcNhrVy5UqWlpaqqqopahVRVVaXS0lKtWrWKC3iBcSbud90bjeJOvBTlvPL7/aaxsdEM1dDQYPx+f9znRlFUbIo78bKMGnAk7sQLONtI99+JYzgnADhn4XBYNTU18Z4GgDjjGhgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7BBgAAGA7oxJgpk6dqhdffFHHjh1Td3e33nvvPeXn50f1rFmzRkePHlV3d7e2b9+unJycqPGMjAy99NJLOnHihI4fP64NGzYoNTV1NKYLAABsJuYBZvLkydq9e7f6+vq0ZMkSXXnllVq5cqWOHz8e6Vm9erUeeughLV++XAUFBerq6tK2bduUkpIS6dm4caOuuuoqLVq0SKWlpbr++uv14x//ONbTBQAANmViWeXl5WbXrl1n7Dl69KhZuXJl5H16errp6ekxd955p5FkZs+ebYwxJj8/P9KzePFiMzAwYLKyskY0D4/HY4wxxuPxxPTnoyiKoihq9Gqk+++YH4H5xje+ob179+qVV15RKBTSO++8owceeCAynp2draysLO3YsSOyraOjQ3v27FFRUZEkqaioSMePH9e+ffsiPTt27FA4HFZBQcGwn5ucnCyPxxNVAADAmWIeYGbOnKkHH3xQH330kRYvXqxnn31W//Zv/6Z7771XkpSZmSlJCoVCUV8XCoUiY5mZmWppaYkaHxgYUFtbW6Tni8rKytTR0RGppqamWP9oAADAIhJj/Q3dbrf27t2rxx57TJK0f/9+5ebmavny5frZz34W64+LKC8v17p16yLvPR4PIQZwILfbLZ/Pp6ysLAWDQdXW1iocDsd7WgDGWMyPwASDQb3//vtR2z744ANNnz5dktTc3CxJ8nq9UT1erzcy1tzcrClTpkSNJyQk6Pzzz4/0fFFvb686OzujCoCz+P1+BQIBVVdXa9OmTaqurlYgEJDf74/31ACMsZgHmN27d+uKK66I2nb55ZfryJEjkqRDhw4pGAyqpKQkMu7xeFRQUKC6ujpJUl1dnTIyMpSXlxfpWbhwodxut/bs2RPrKQOwAb/fr8rKStXX16uwsFBpaWkqLCxUfX29KisrCTHAOBTTq4fnzZtnent7TVlZmbnsssvMXXfdZU6ePGm++c1vRnpWr15t2trazC233GJyc3PN5s2bTUNDg0lJSYn0vP7662bfvn1m/vz55tprrzUHDx40GzdujPlVzBRFWb/cbrdpbGw0W7ZsMS6XK2rM5XKZLVu2mIaGBuN2u+M+V4qizq3OYv8d+w+/+eabzXvvvWd6enrM+++/bx544IHTetasWWOCwaDp6ekx27dvN7NmzYoaz8jIMBs3bjQdHR2mvb3dPPfccyY1NXU0fgEURVm8iouLjTHGFBQUDDteWFhojDGmuLg47nOlKOrcKq4BxgpFgKEo59SyZcuMMeaP/icmLS3NGGPMsmXL4j5XiqLOreJ2HxgAiLVgMChJys3NHXZ8cPtgHwDnI8AAsLza2lodOnRIjz76qFwuV9SYy+VSWVmZGhsbVVtbG6cZAhhrBBgAlhcOh7Vy5UqVlpaqqqoqahVSVVWVSktLtWrVKu4HA4wzcT/fNRrFNTAU5bzy+/2msbHRDNXQ0GD8fn/c50ZRVGxqpPtv1x9eOI7H41FHR4fS09O5qR3gIMnJyfrnf/5n5eTkKBAIaOXKlert7Y33tADEyNnsv+OetkajOAJDUc6riooK09vbG3UEpre311RUVMR9bhRFxaZYhQTAUSoqKrR69Wq1trbq/vvvl9fr1f3336/W1latXr1aFRUV8Z4igDHEKSQAlpeYmKju7m61trZq2rRpURfrut1uNTU16YILLtDEiRPV398fx5kCOFcj3X9zBAaA5a1YsUJJSUl67LHHTltpFA6H9Q//8A9KSkrSihUr4jRDAGONAAPA8i677DJJ0quvvjrs+OD2wT4AzkeAAWB5DQ0NkqTS0tJhxwe3D/YBcD6ugQFgeVwDA4wfXAMDwDH6+/u1bt06eb1eNTU16YEHHlBmZqYeeOABNTU1yev1at26dYQXYJyJ+5rv0SjuA0NRzivuA0NRzi/uxMspJMCREhMTtWLFCl122WVqaGjQ+vXrOfICOMhI998EGAAAYBlcAwMAAByLAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGyHAAMAAGwnMd4TAICz4Xa75fP5lJWVpWAwqNraWoXD4XhPC8AY4wgMANvw+/0KBAKqrq7Wpk2bVF1drUAgIL/fH++pARhjHIEBYAt+v1+VlZV67bXXVFVVpQkTJqinp0c5OTmqrKzU7bffrs2bN8d7mgDGiEuSifckRoPH41FHR4fS09PV2dkZ7+kAOAdut1uBQED9/f269NJLlZSUFBnr6+vT4cOHlZCQoFmzZnE6CbC5ke6/OYUEwPJ8Pp+ys7OVk5Oj1tZW3X///fJ6vbr//vvV2tqqnJwczZw5Uz6fL95TBTBGOIUEwPIuvvhiSVJLS4umTZsWOcryk5/8RC+88IKOHj0qr9cb6QPgfByBAWB5hYWFkqQNGzacdoooHA7rJz/5SVQfAOcjwACwjXnz5snlckVtc7lcysvLi9OMAMQLAQaA5QUCAUnSokWLVFVVpcLCQqWlpamwsFBVVVVatGhRVB8A52MVEgDLS0xMVHd3t06ePKn29nZlZ2dHxhobG5WRkaG0tDRNnDhR/f39cZwpgHPFKiQAjtHf369169Zp8uTJmjBhgtauXasHH3xQa9eu1cSJEzV58mStW7eO8AKMM8aJ5fF4jDHGeDyeuM+FoqjYVEVFhent7TVD9fb2moqKirjPjaKo2NRI99+cQgJgK4mJiVqxYoUuu+wyNTQ0aP369Rx5ARxkpPtv7gMDwFbC4bD279+vUCikYDDInXeBcYprYADYBg9zBDCIAAPAFgYf5jhlypSo7VOmTFFlZSUhBhhnCDAALM/tduvZZ5+Vy+XSzp07o+4Ds3PnTrlcLj3zzDNyu/mTBowncb/ieDSKVUgU5ZxasGCBMcaYXbt2GZfLFTXmcrnMrl27jDHGLFiwIO5zpSjq3Gqk+2/+uwLA8m644QZJ0j/+4z/KGBM1ZozR448/HtUHwPkIMAAAwHYIMAAsr7q6WpL0xBNPDPswx8EjMIN9AJyPAAPA8mpqahQKhXTdddcN+zDH6667Ts3NzaqpqYn3VAGMoVG9GOdv//ZvjTHGPPXUU5FtKSkp5umnnzbHjh0znZ2dprKy0kyZMiXq6y655BLz6quvmq6uLhMKhcwPf/hDk5CQEPOLgCiKskf5/X4zMDBgTp48GfUogZMnT5qBgQHj9/vjPkeKos69zmL/PXqTmDdvnmlsbDT79++PCjDPPPOMOXLkiFmwYIHJy8szv/nNb8yvf/3ryLjb7TbvvfeeefPNN83cuXPNTTfdZFpaWswPfvCD0fgFUBRlk/L7/aaxsTEqwDQ0NBBeKMpBFfcAk5qaag4ePGhKSkrMW2+9FQkw6enp5tSpU+a2226L9F5xxRXGGGMKCgqMJHPTTTeZ/v7+qKMy3/3ud017e7tJSkqK9S+AoigbldvtNsXFxWbZsmWmuLjYuN3uuM+JoqjYVdyXUa9fv16vvfaadu7cGbU9Pz9fycnJ2rFjR2TbwYMHdeTIERUVFUmSioqKVF9fr5aWlkjPtm3bNGnSJF111VXDfl5ycrI8Hk9UAXCecDismpoa/cd//Idqamp4FhIwTo3KwxzvvPNO5eXlaf78+aeNZWZm6tSpUzpx4kTU9lAopMzMzEhPKBQ6bXxwbDhlZWWRlQgAAMDZYn4E5uKLL9a//uu/6u6779apU6di/e3/qPLycqWnp0dq2rRpY/bZAABgbMU8wOTn58vr9eqdd95RX1+f+vr6dMMNN+ihhx5SX1+fQqGQUlJSNGnSpKiv83q9am5uliQ1NzfL6/WeNj44Npze3l51dnZGFQAAcKaYB5idO3cqNzdXX/3qVyP19ttva+PGjfrqV7+qvXv3qre3VyUlJZGvufzyyzVjxgzV1dVJkurq6jRnzhxddNFFkZ5FixbpxIkTev/992M9ZQA24na7VVxcrGXLlqm4uJgHOALj2KhfUTx0FZL02TLqw4cPmxtuuMHk5eWZ3bt3m927d39+ZfEfllFv3brVXH311ebrX/+6CYVCLKOmqHFewy2jbmxsZBk1RTmo4r6Memh9McAM3siutbXVnDx50vz85z83Xq836mumT59uXnvtNdPV1WVaWlrM2rVruZEdRY3jGryR3ZYtW0xBQYFJTU01BQUFZsuWLdzIjqIcVCPdf7v+8MJxPB6POjo6lJ6ezvUwgM253W4FAgHV19dr6dKlUU+kdrlcqqqqUm5urmbNmsWyasDmRrr/5uQxAMvz+XzKzs7Wk08+GRVeJMkYo/Lycs2cOVM+ny9OMwQw1ggwACwvKytLknTgwIFhxwe3D/YBcD4CDADLCwaDkqTc3Nxhxwe3D/YBcD4CDADLq62t1aFDh/Too4/K5XJFjblcLpWVlamxsVG1tbVxmiGAsUaAAWB54XBYK1euVGlpqaqqqlRYWKi0tDQVFhaqqqpKpaWlWrVqFRfwAuNM3JdMjUaxjJqinFfD3QemoaGBJdQU5aBiGTXLqAFHcrvd8vl8ysrKUjAYVG1tLUdeAAcZ6f57VJ5GDQCjJRwOq6amJt7TABBnXAMDAABshwADAABsh1NIAGyFa2AASByBAWAjfr9fgUBA1dXV2rRpk6qrqxUIBOT3++M9NQBjjCMwAGzB7/ersrJSr776qtauXauenh5NmDBBN910kyorK3X77bdr8+bN8Z4mgDHCMmoAljf4NOpjx47pwgsvVHZ2dmTs0KFDOnbsmC644AKeRg04AE+jBuAYg0+jzs/PV319fdSdeOvr65Wfn8/TqIFxhgADwPKmTp0qSXrjjTe0dOlS7dmzR11dXdqzZ4+WLl2qrVu3RvUBcD4CDADLmzJliiTpF7/4hYyJPuttjIlc+zLYB8D5CDAALO+TTz6RJP3FX/zFsE+jXrp0aVQfAOdjFRIAy2tqapIkLVmyRFu2bNEbb7wRWYW0ZMkSLVmyJKoPgPOxCgmA5Q2uQurv79ell16qpKSkyFhfX58OHz6shIQEViEBDsAqJACOEQ6H9corrygnJ0etra1au3atHnzwQa1du1atra3KycnRf/3XfxFegHGEIzAALO9M94FpbGxUa2sr94EBHGKk+2+ugQFgeYP3gbnrrrv09ttvn/YspGuuuUZ1dXXy+XyqqamJ93QBjAECDADLy8rKkiQdOHBA4XD4tJBy4MCBqD4Azsc1MAAsLxgMSpJyc3PldrtVXFysZcuWqbi4WG63W7m5uVF9AJyPa2AAWB7PQgLGD1YhAXCMwVVI8+bN0yWXXBI1dskll2jevHmsQgLGGQIMAMtzu9361re+FXn9xTFJuu+++04bA+Bc/GsHYHnFxcXyer2SpJ6enqixwfeZmZkqLi4e87kBiA8CDADLW7BgQeT1zp07VVhYqLS0NBUWFmrnzp3D9gFwNpZRA7C8GTNmSJLq6+u1dOnSyBOp9+zZo6VLl2r//v26+uqrI30AnI8jMAAsb/AJ1IPB5U/1AXA+AgwAyzt8+LAk6eqrr1ZVVVXUKaSqqirNmTMnqg+A8xFgAFjeW2+9FXldUlKiuro6dXZ2qq6uTiUlJcP2AXA2AgwAy6upqVEoFJL0x08TNTc38xwkYBwhwACwvHA4rAcffFDGGE2YMCFqbOLEiTLG6Hvf+x43sgPGEQIMAFsoKCiQy+XSwMBA1PaBgQG5XC4VFBTEaWYA4oFnIQGwvMTERHV3d+vkyZNqb28/7VlIkydPVlpamiZOnKj+/v44zhTAueJZSAAcY8WKFUpKStKkSZM0ZcqUqLEpU6Zo0qRJSkpK0ooVK+I0QwBjjQADwPJycnIkfXYB73B34h28sHewD4DzEWAAWN5gQPnoo490++23q7CwUOXl5SosLNTtt9+uQCAQ1QfA+XiUAADLa29vlyRdfPHF6urqUlJSUmRs7dq16uvri+oD4HwEGACWN7jy6ItLqKXPLvBNTEyM6gPgfJxCAmB5tbW1kddffB7S0PdD+wA4GwEGgOUNPutIkrZu3apAIKBjx44pEAho69atw/YBcDYCDADLu+666yKvlyxZopycHF144YXKycnRkiVLhu0D4GwEGACWd/LkyZj2AbA/LuIFYHmbNm3SvffeK0l69dVX9emnn2ry5Mlqb2/Xeeedp9LS0kgfgPGBAAPA8r7zne9EXpeWlkbd72XoRbzf+c53oq6JAeBcnEICYHkjvTiXi3iB8YMAA8Dyjh8/Hnnd3d0dNTb0/dA+AM7GKSQAlrdv3z7Nnz9fknTBBReosLBQWVlZCgaD+p//+R/19PRE+gCMDxyBAWB5Q59A3dXVpbKyMk2fPl1lZWXq6uoatg+As3EEBoDldXZ2Svrsgl23263Fixdr8eLFkW3GGLlcrkgfAOfjCAwAy3vxxRclffa06eEeJTC4KmmwD4DzEWAAWF5NTc2ffFDjwMCAampqxmhGAOKNAAPA8nw+nxISEiQp6h4wQ98nJCTI5/ON+dwAxAcBBoDlLViwQJLU1tY27Pjg9sE+AM5HgAFgedOnT5cknX/++cOOD24f7APgfDEPMH/3d3+n3/72t+ro6FAoFNLmzZt1+eWXR/WkpKTo6aef1rFjx9TZ2anKysrTlj9ecsklevXVV9XV1aVQKKQf/vCHkUPIAMaXpqamyOsvXgsz9P3QPgDOFvMAU1xcrPXr16uwsFCLFi1SUlKS3nzzTU2cODHS89RTT+mWW27RX/7lX6q4uFhTp07VL37xi88n5XbrtddeU3Jysq699lrdd999+ta3vqUnnngi1tMFYAMZGRmR18eOHdOmTZu0YcMGbdq0SceOHRu2D4DzmdGsCy+80BhjjM/nM5JMenq6OXXqlLntttsiPVdccYUxxpiCggIjydx0002mv7/fTJkyJdLz3e9+17S3t5ukpKQRfa7H4zHGGOPxeEb156MoavSrurraGGNMOBw24XDYDDV0W3V1ddznSlHUudVI99+jfg3MpEmTJH1+kV1+fr6Sk5O1Y8eOSM/Bgwd15MgRFRUVSZKKiopUX1+vlpaWSM+2bds0adIkXXXVVcN+TnJysjweT1QBcIbJkydHXg93H5jh+gA426gGGJfLpX/5l3/Rr3/9a/3v//6vJCkzM1OnTp3SiRMnonpDoZAyMzMjPaFQ6LTxwbHhlJWVqaOjI1KcCwec48CBA5I+Cyu///3vo8aOHDkSCTGDfQCcb1QfJbB+/Xrl5ubquuuuG82PkSSVl5dr3bp1kfcej4cQAzjE4H94XC6XzjvvPK1du1aNjY2aOXOm7rnnnsi9YL74HyMAzjVqAeZHP/qRSktLdf3110cFiebmZqWkpGjSpElRf2y8Xq+am5sjPddcc03U9/N6vZGx4fT29qq3tzfWPwYACxi60sjr9eqRRx6JvB96CulP3a0XgHOMyimkH/3oR/L7/Vq4cKEOHz4cNbZv3z719vaqpKQksu3yyy/XjBkzVFdXJ0mqq6vTnDlzdNFFF0V6Fi1apBMnTuj9998fjSkDsLCGhobI6zNdAzO0D4DzxfTq4fXr15vjx4+b66+/3ni93kidd955kZ5nnnnGHD582Nxwww0mLy/P7N692+zevfvzK4vdbvPee++ZrVu3mquvvtp8/etfN6FQyPzgBz+I+VXMFEVZvxITE01vb69pa2szhw4dilqF1NjYaNra2kxvb69JTEyM+1wpijq3Oov9d2w/+I+57777Ij0pKSnm6aefNq2trebkyZPm5z//ufF6vVHfZ/r06ea1114zXV1dpqWlxaxdu9YkJCSMxi+AoigbVEVFhQmHw6avry/qb0tfX58Jh8OmoqIi7nOkKOrcK24BxipFgKEoZ5Xf7z/jfWD8fn/c50hR1LmXZe4DAwDnyu1269lnn5Uk9fT0RI0Nvn/mmWfkdvMnDRgvRnUZNQDEQnFxsbxer4wx+tWvfqWenh5NnjxZ7e3tmjBhgm6++WZlZmaquLhYb731VrynC2AMEGAAWN6CBQskfXZH75tvvjly3xdJMsaora1NF1xwgRYsWECAAcYJjrcCsLzp06dLks4///xhxwe3D/YBcD4CDADLCwaDkddnug/M0D4AzsYpJACW95WvfCXyuqWlRW+99Za6urqUmpqqBQsWRO7UPbQPgLMRYABY3ty5cyOvvV6v7rrrrsj7oUdghvYBcDZOIQGwvPPOOy+mfQDsjwADwPIOHDgQeX2ma2CG9gFwNgIMAMsb+pDG3t5e7d27V7t27dLevXujnkLPwxyB8YNrYABYXkFBQeR1SkqK5s2bF3k/9AjM0D4AzsYRGACWl5KSEtM+APZHgAFgeTU1NZHXZ7oGZmgfAGcjwACwvEAgENM+APZHgAFgeV/72tcir4c+B+mL74f2AXA2AgwAy5s4cWJM+wDYHwEGgOV98sknMe0DYH8EGACWN/iso1j1AbA/AgwAy7vyyitj2gfA/ggwACwvOTk5pn0A7I8AA8Dyenp6YtoHwP4IMAAsr6+vL6Z9AOyPAAPA8pKSkmLaB8D+CDAALK+7uzumfQDsjwADwPI++uijmPYBsD8CDADLu/HGG2PaB8D+CDAALC8lJSWmfQDsjwADwPKMMTHtA2B/BBgAltfb2xvTPgD2R4ABYHmJiYkx7QNgfwQYAJbndo/sT9VI+wDYH//aAQCA7RBgAACA7RBgAFiey+WKaR8A+yPAAAAA2yHAAAAA2yHAAAAA2yHAAAAA2yHAAAAA2yHAAAAA2yHAAAAA2yHAAAAA2yHAAAAA2yHAAAAA2yHAAAAA2yHAAAAA2yHAAAAA2yHAAAAA20mM9wQAjA8TJkzQ7NmzR/1z/uzP/uysv+bDDz9UT0/PKMwGwGghwAAYE7Nnz9Y777xzTt/D5XKdcZvb7f5Sn5GXl6ff/e535zQ3AGOLAANgTHz44YfKy8v7Ul/79ttvKyEhQcYYSdGhZei2gYEBzZ8//0vNDYC9EGAAjImenp4vfZTjxhtv1K9+9asz9hhjdOONN3IkBRgnXJJMvCcxGjwejzo6OpSenq7Ozs54TwfAOerv75fb/dm6g+GOwITDYSUm8n8ywO5Guv9mFRIAW0hMTFQ4HB52jPACjD8EGAC2kZiYqIULF2pgYECSNDAwoIULFxJegHGIf/UA/qScnBx5PJ54T0OSdOLECd1zzz16+eWXdc899+jEiRNfaun0aOjs7FQgEIj3NIBxgQAD4IxycnL00UcfxXsaw3r55ZfjPYXTzJo1ixADjAECDIAzGjzycvfdd+uDDz6I82w+c9555+nSSy/V4cOH9emnn8Z7OpKkr3zlK9q4caNljlQBTmfpAPO9731PjzzyiDIzM/Xuu+/q+9//vt5+++14TwsYd4w+lTHtkjriPRVJ0qefdujDD1viPY0oxrTLyBphChgPLBtg7rjjDq1bt07Lly/Xnj179PDDD2vbtm264oor9Mknn8R7esC4MXHiRElHtPHlB+M9FRs4Eu8JAOOGZQPM3/zN3+jf//3f9cILL0iSli9frptvvll//dd/rX/6p3+K7+SAceSz5xfNkJQZ76nYQAr3nQLGiCUDTFJSkvLz81VeXh7ZZozRjh07VFRUFMeZAeNPVVWVpM9ut9/d3f2lv8/gdStWFKtraViFBIwdSwaYCy+8UImJiQqFQlHbQ6HQH32abXJyslJSUiLvuZAOiI3W1lY999xzMfledXV1Mfk+AOCYG9mVlZWpo6MjUk1NTfGeEgAAGCWWDDDHjh1Tf3+/vF5v1Hav16vm5uZhv6a8vFzp6emRmjZt2lhMFQAAxIElA0xfX5/27dunkpKSyDaXy6WSkpI/egi6t7dXnZ2dUQUAAJzJktfASNK6dev005/+VHv37tVvf/tbPfzww0pNTdXzzz8f76kBAIA4s2yAeeWVV3TRRRfpiSeeUGZmpvbv36+bbrpJLS3WunkVAAAYey5JJt6TGA0ej0cdHR1KT0/ndBIAADYx0v23Ja+BAQAAOBMCDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB0CDAAAsB3L3sguVngqNQAA9jHS/bZjA8zgL4CnUgMAYD8ej+eMN7Jz7J14JWnq1KnchRdwII/Ho6amJk2bNo1/44ADeTweHT169Iw9jg4wAJyJR4UA4CJeAABgOwQYAABgOwQYALZz6tQpPf744zp16lS8pwIgTrgGBgAA2A5HYAAAgO0QYAAAgO0QYAAAgO0QYAAAgO0QYADYhs/n0y9/+Us1NTXJGKNbb7013lMCECcEGAC2kZqaqnfffVcrVqyI91QAxJljH+YIwHm2bt2qrVu3xnsaACyAIzAAAMB2CDAAAMB2CDAAAMB2CDAAAMB2CDAAAMB2WIUEwDZSU1OVk5MTeZ+dna25c+eqra1NH3/8cRxnBmCs8TRqALZRXFys6urq07a/8MIL+qu/+quxnxCAuCHAAAAA2+EaGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDsEGAAAYDv/H3jDpfiOm9IDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "freq_dict = {}\n",
    "# for pc in clips:\n",
    "#     freq_dict[pc.word] = freq_dict.get(pc.word, 0) + 1\n",
    "\n",
    "freqs = list(filter(lambda x: 5 < x < 200000, freq_dict.values()))\n",
    "\n",
    "plt.boxplot(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_clips(clips: List[PronunciationClip], min_freq: int = 20,\n",
    "                 max_freq: int = 200) -> List[PronunciationClip]:\n",
    "    freq_dict = {}\n",
    "    for pc in clips:\n",
    "        freq_dict[pc.word] = freq_dict.get(pc.word, 0) + 1\n",
    "    included_words = list(filter(lambda w: min_freq < freq_dict[w] < max_freq,\n",
    "                                 freq_dict.keys()))\n",
    "    return list(filter(lambda c: c.word in included_words, clips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'freq_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[1;32m----> 3\u001b[0m wf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m<\u001b[39m x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m, \u001b[43mfreq_dict\u001b[49m\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(wf)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m words remain after filtering\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocab.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'freq_dict' is not defined"
     ]
    }
   ],
   "source": [
    "wf = dict(filter(lambda x: 50 < x[1] < 300, freq_dict.items()))\n",
    "print(f'{len(wf)} words remain after filtering')\n",
    "\n",
    "with open('vocab.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(wf.keys()))\n",
    "    print('wrote vocabulary file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = load_vocab()\n",
    "# clips = load_utterances(20_000, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.path.join('parsed_files', 'raw_clips')\n",
    "# utter_path = os.path.join('parsed_files', 'raw_utterance')\n",
    "# os.makedirs(path, exist_ok = True)\n",
    "# os.makedirs(utter_path, exist_ok = True)\n",
    "# for i, c in enumerate(clips):\n",
    "#     og = c.audio.set_channels(1).set_frame_rate(16000)\n",
    "#     og.export(os.path.join(utter_path, f'{c.word}_{i}.wav'), format=\"wav\")\n",
    "#     a = gen_clip(c.audio)\n",
    "#     a.export(os.path.join(path, f'{c.word}_{i}.wav'), format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_clips = make_noise_playlist(os.path.join('audio', 'music'), 200)\n",
    "outdoor_clips = make_noise_playlist(os.path.join('audio', 'outside_rural'))\n",
    "babble_clips = make_noise_playlist(os.path.join('audio', 'babble'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "m_path = os.path.join('parsed_files', 'music')\n",
    "o_path = os.path.join('parsed_files', 'outdoor')\n",
    "b_path = os.path.join('parsed_files', 'babble')\n",
    "\n",
    "os.makedirs(m_path, exist_ok = True)\n",
    "os.makedirs(o_path, exist_ok = True)\n",
    "os.makedirs(b_path, exist_ok = True)\n",
    "\n",
    "def overlay_noise_clips(clip: PronunciationClip, noise: List[AudioSegment],\n",
    "                        SNRs: List[float], paths: List[os.PathLike],\n",
    "                        i: Optional[int], starttime: Optional[float]) -> None:\n",
    "    a = gen_clip(clip.audio)\n",
    "    if i > 1 and (i - 1) % 200 == 0:\n",
    "        print(f'Parsing {i+1}-th file, {time.time() - starttime}s since start.')\n",
    "    for n, snr, path in zip(noise, SNRs, paths):\n",
    "        noisy_clip = overlay_noise(snr, a, n)\n",
    "        noisy_cgram = aa_cgram(audio_to_cgram(noisy_clip))\n",
    "\n",
    "        fname = f'{clip.word}_{i}' if i is not None else clip.word\n",
    "\n",
    "        noisy_clip.export(os.path.join(path, fname + '.wav'), format=\"wav\")\n",
    "        np.save(os.path.join(path, fname + '.npy'), noisy_cgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nwong\\AppData\\Local\\Temp\\ipykernel_6532\\2912052705.py:19: RuntimeWarning: invalid value encountered in cast\n",
      "  noise_array = array.array(signal.array_type, np.round(noise_samples).astype(np.int32))\n",
      "c:\\Users\\nwong\\Documents\\nick-repo\\.conda\\Lib\\site-packages\\pycochleagram-0.1-py3.11.egg\\pycochleagram\\cochleagram.py:135: RuntimeWarning: divide by zero encountered in log10\n",
      "  freqs_to_plot = np.log10(freqs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 201-th file, 270.7059586048126s since start.\n",
      "Parsing 401-th file, 530.517341375351s since start.\n",
      "Parsing 601-th file, 809.418744802475s since start.\n",
      "Parsing 801-th file, 1086.0549218654633s since start.\n",
      "Parsing 1001-th file, 1367.92067694664s since start.\n",
      "Parsing 1201-th file, 1644.0014822483063s since start.\n",
      "Parsing 1401-th file, 1912.5640633106232s since start.\n",
      "Parsing 1601-th file, 2192.926835536957s since start.\n",
      "Parsing 1801-th file, 2470.6881515979767s since start.\n",
      "Parsing 2001-th file, 2751.555253982544s since start.\n",
      "Parsing 2201-th file, 3034.0029985904694s since start.\n",
      "Parsing 2401-th file, 3299.276870727539s since start.\n",
      "Parsing 2601-th file, 3578.7631669044495s since start.\n",
      "Parsing 2801-th file, 3860.706557750702s since start.\n",
      "Parsing 3001-th file, 4124.483392715454s since start.\n",
      "Parsing 3201-th file, 4406.435935258865s since start.\n",
      "Parsing 3401-th file, 4678.017326831818s since start.\n",
      "Parsing 3601-th file, 4962.225158929825s since start.\n",
      "Parsing 3801-th file, 5237.8138835430145s since start.\n",
      "Parsing 4001-th file, 5516.944722414017s since start.\n",
      "Parsing 4201-th file, 5787.441699743271s since start.\n",
      "Parsing 4401-th file, 6050.50537276268s since start.\n",
      "Parsing 4601-th file, 6331.188761234283s since start.\n",
      "Parsing 4801-th file, 6595.1048057079315s since start.\n",
      "Parsing 5001-th file, 6876.874137163162s since start.\n",
      "Parsing 5201-th file, 7154.106064319611s since start.\n",
      "Parsing 5401-th file, 7424.514765739441s since start.\n",
      "Parsing 5601-th file, 7700.544395685196s since start.\n",
      "Parsing 5801-th file, 7985.737582683563s since start.\n",
      "Parsing 6001-th file, 8260.696755170822s since start.\n",
      "Parsing 6201-th file, 8538.419895648956s since start.\n",
      "Parsing 6401-th file, 8820.438431739807s since start.\n",
      "Parsing 6601-th file, 9098.639641046524s since start.\n",
      "Parsing 6801-th file, 9377.935492515564s since start.\n",
      "Parsing 7001-th file, 9641.044960260391s since start.\n",
      "Parsing 7201-th file, 9922.683311700821s since start.\n",
      "Parsing 7401-th file, 10192.336149215698s since start.\n",
      "Parsing 7601-th file, 10459.423986196518s since start.\n",
      "Parsing 7801-th file, 10739.47325539589s since start.\n",
      "Parsing 8001-th file, 11010.883056879044s since start.\n",
      "Parsing 8201-th file, 11298.084961414337s since start.\n",
      "Parsing 8401-th file, 11594.40601348877s since start.\n",
      "Parsing 8601-th file, 11871.84086894989s since start.\n",
      "Parsing 8801-th file, 12147.054782629013s since start.\n",
      "Parsing 9001-th file, 12430.000423908234s since start.\n",
      "Parsing 9201-th file, 12711.13805770874s since start.\n",
      "Parsing 9401-th file, 12991.119759082794s since start.\n",
      "Parsing 9601-th file, 13256.905406475067s since start.\n",
      "Parsing 9801-th file, 13532.638498544693s since start.\n",
      "Parsing 10001-th file, 13806.743838787079s since start.\n",
      "Parsing 10201-th file, 14077.694905281067s since start.\n",
      "Parsing 10401-th file, 14362.639299631119s since start.\n",
      "Parsing 10601-th file, 14650.853780984879s since start.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# music is -6dB mean, other noise is -3dB mean. all with 2dB variance\n",
    "np.random.seed(123)\n",
    "N = len(clips)\n",
    "music_snr = np.random.normal(-6, 2, N)\n",
    "outdoor_snr = np.random.normal(-3, 2, N)\n",
    "babble_snr = np.random.normal(-3, 2, N)\n",
    "\n",
    "random.seed(123)\n",
    "starttime = time.time()\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(\n",
    "        overlay_noise_clips,\n",
    "        clip,\n",
    "        [\n",
    "            random.choice(music_clips),\n",
    "            random.choice(outdoor_clips),\n",
    "            random.choice(babble_clips)\n",
    "        ],\n",
    "        [music_snr[i], outdoor_snr[i], babble_snr[i]],\n",
    "        [m_path, o_path, b_path],\n",
    "        i, starttime\n",
    "    ) for i, clip in enumerate(clips)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Load audio files functions, vocabulary, word-to-index dictionary, cochleagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "def make_word2ind(clips: List[PronunciationClip]) -> Dict[str, int]:\n",
    "    words2ind = {}\n",
    "    words = set(c.word for c in clips)\n",
    "    for i, w in enumerate(words):\n",
    "        words2ind[w] = i\n",
    "    return words2ind\n",
    "\n",
    "def load_vocab(vocab_file: str = 'vocab.txt') -> List[str]:\n",
    "    vocab = []\n",
    "    with open(vocab_file, 'r') as f:\n",
    "        vocab = f.read().strip().split('\\n')\n",
    "    print(f'Loaded vocabulary {vocab_file} with {len(vocab)} words.')\n",
    "    return vocab\n",
    "\n",
    "def vocab_word2ind(vocab: List[str]) -> Dict[str, int]:\n",
    "    x = {}\n",
    "    for i, w in enumerate(vocab):\n",
    "        x[w] = i\n",
    "    return x\n",
    "\n",
    "def filter_clips_vocab(clips: List[PronunciationClip], vocab: List[str]\n",
    "                 ) -> List[PronunciationClip]:\n",
    "    return list(filter(lambda c: c.word in vocab, clips))\n",
    "\n",
    "def load_clips(path: str = 'parsed_files/raw_clips') -> List[PronunciationClip]:\n",
    "    clips = []\n",
    "    for fp in os.listdir(path):\n",
    "        if not fp.endswith('.wav'):\n",
    "            continue\n",
    "        filename = os.path.join(path, fp)\n",
    "        audio = AudioSegment.from_file(filename)\n",
    "        word = fp.split('_')[0]\n",
    "        clips.append(PronunciationClip(word, audio))\n",
    "    return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocabulary vocab.txt with 237 words.\n"
     ]
    }
   ],
   "source": [
    "clips = load_clips()\n",
    "vocab = load_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 words from 20003 clips\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'term': 0,\n",
       " 'northern': 1,\n",
       " 'september': 2,\n",
       " 'language': 3,\n",
       " 'title': 4,\n",
       " 'many': 5,\n",
       " 'another': 6,\n",
       " 'found': 7,\n",
       " 'throughout': 8,\n",
       " 'times': 9,\n",
       " 'including': 10,\n",
       " 'company': 11,\n",
       " 'saint': 12,\n",
       " 'than': 13,\n",
       " 'against': 14,\n",
       " 'made': 15,\n",
       " 'school': 16,\n",
       " 'zero': 17,\n",
       " 'part': 18,\n",
       " 'january': 19,\n",
       " 'york': 20,\n",
       " 'eleven': 21,\n",
       " 'canada': 22,\n",
       " 'album': 23,\n",
       " 'forty': 24,\n",
       " 'church': 25,\n",
       " 'began': 26,\n",
       " 'died': 27,\n",
       " 'developed': 28,\n",
       " 'best': 29,\n",
       " 'into': 30,\n",
       " 'park': 31,\n",
       " 'sixteen': 32,\n",
       " 'union': 33,\n",
       " 'hundred': 34,\n",
       " 'people': 35,\n",
       " 'east': 36,\n",
       " 'based': 37,\n",
       " 'been': 38,\n",
       " 'seventy': 39,\n",
       " 'members': 40,\n",
       " 'second': 41,\n",
       " 'held': 42,\n",
       " 'music': 43,\n",
       " 'what': 44,\n",
       " 'high': 45,\n",
       " 'american': 46,\n",
       " 'eight': 47,\n",
       " 'sixty': 48,\n",
       " 'where': 49,\n",
       " 'australia': 50,\n",
       " 'popular': 51,\n",
       " 'could': 52,\n",
       " 'history': 53,\n",
       " 'season': 54,\n",
       " 'political': 55,\n",
       " 'time': 56,\n",
       " 'british': 57,\n",
       " 'because': 58,\n",
       " 'while': 59,\n",
       " 'series': 60,\n",
       " 'family': 61,\n",
       " 'government': 62,\n",
       " 'published': 63,\n",
       " 'around': 64,\n",
       " 'fifteen': 65,\n",
       " 'house': 66,\n",
       " 'national': 67,\n",
       " 'form': 68,\n",
       " 'some': 69,\n",
       " 'small': 70,\n",
       " 'november': 71,\n",
       " 'home': 72,\n",
       " 'well': 73,\n",
       " 'would': 74,\n",
       " 'song': 75,\n",
       " 'such': 76,\n",
       " 'before': 77,\n",
       " 'film': 78,\n",
       " 'television': 79,\n",
       " 'different': 80,\n",
       " 'number': 81,\n",
       " 'modern': 82,\n",
       " 'both': 83,\n",
       " 'king': 84,\n",
       " 'eighteen': 85,\n",
       " 'former': 86,\n",
       " 'created': 87,\n",
       " 'general': 88,\n",
       " 'largest': 89,\n",
       " 'these': 90,\n",
       " 'system': 91,\n",
       " 'place': 92,\n",
       " 'will': 93,\n",
       " 'same': 94,\n",
       " 'city': 95,\n",
       " 'them': 96,\n",
       " 'jesus': 97,\n",
       " 'become': 98,\n",
       " 'became': 99,\n",
       " 'like': 100,\n",
       " 'period': 101,\n",
       " 'role': 102,\n",
       " 'development': 103,\n",
       " 'very': 104,\n",
       " 'species': 105,\n",
       " 'fiction': 106,\n",
       " 'those': 107,\n",
       " 'without': 108,\n",
       " 'this': 109,\n",
       " 'since': 110,\n",
       " 'lake': 111,\n",
       " 'their': 112,\n",
       " 'states': 113,\n",
       " 'thirteen': 114,\n",
       " 'similar': 115,\n",
       " 'club': 116,\n",
       " 'although': 117,\n",
       " 'state': 118,\n",
       " 'public': 119,\n",
       " 'social': 120,\n",
       " 'science': 121,\n",
       " 'station': 122,\n",
       " 'sometimes': 123,\n",
       " 'under': 124,\n",
       " 'europe': 125,\n",
       " 'town': 126,\n",
       " 'international': 127,\n",
       " 'written': 128,\n",
       " 'they': 129,\n",
       " 'were': 130,\n",
       " 'over': 131,\n",
       " 'following': 132,\n",
       " 'twelve': 133,\n",
       " 'even': 134,\n",
       " 'population': 135,\n",
       " 'among': 136,\n",
       " 'often': 137,\n",
       " 'named': 138,\n",
       " 'during': 139,\n",
       " 'death': 140,\n",
       " 'game': 141,\n",
       " 'human': 142,\n",
       " 'built': 143,\n",
       " 'nine': 144,\n",
       " 'between': 145,\n",
       " 'seventeen': 146,\n",
       " 'widely': 147,\n",
       " 'president': 148,\n",
       " 'london': 149,\n",
       " 'various': 150,\n",
       " 'generally': 151,\n",
       " 'thirty': 152,\n",
       " 'within': 153,\n",
       " 'when': 154,\n",
       " 'player': 155,\n",
       " 'played': 156,\n",
       " 'year': 157,\n",
       " 'located': 158,\n",
       " 'fifty': 159,\n",
       " 'each': 160,\n",
       " 'economic': 161,\n",
       " 'early': 162,\n",
       " 'south': 163,\n",
       " 'line': 164,\n",
       " 'england': 165,\n",
       " 'usually': 166,\n",
       " 'then': 167,\n",
       " 'area': 168,\n",
       " 'business': 169,\n",
       " 'large': 170,\n",
       " 'include': 171,\n",
       " 'english': 172,\n",
       " 'known': 173,\n",
       " 'later': 174,\n",
       " 'countries': 175,\n",
       " 'name': 176,\n",
       " 'person': 177,\n",
       " 'others': 178,\n",
       " 'north': 179,\n",
       " 'ninety': 180,\n",
       " 'eighty': 181,\n",
       " 'book': 182,\n",
       " 'military': 183,\n",
       " 'america': 184,\n",
       " 'episode': 185,\n",
       " 'united': 186,\n",
       " 'games': 187,\n",
       " 'only': 188,\n",
       " 'called': 189,\n",
       " 'currently': 190,\n",
       " 'have': 191,\n",
       " 'long': 192,\n",
       " 'major': 193,\n",
       " 'using': 194,\n",
       " 'video': 195,\n",
       " 'through': 196,\n",
       " 'original': 197,\n",
       " 'being': 198,\n",
       " 'more': 199,\n",
       " 'computer': 200,\n",
       " 'team': 201,\n",
       " 'william': 202,\n",
       " 'works': 203,\n",
       " 'show': 204,\n",
       " 'group': 205,\n",
       " 'much': 206,\n",
       " 'point': 207,\n",
       " 'there': 208,\n",
       " 'world': 209,\n",
       " 'until': 210,\n",
       " 'born': 211,\n",
       " 'however': 212,\n",
       " 'million': 213,\n",
       " 'university': 214,\n",
       " 'about': 215,\n",
       " 'canadian': 216,\n",
       " 'years': 217,\n",
       " 'life': 218,\n",
       " 'common': 219,\n",
       " 'football': 220,\n",
       " 'october': 221,\n",
       " 'work': 222,\n",
       " 'still': 223,\n",
       " 'audio': 224,\n",
       " 'released': 225,\n",
       " 'cent': 226,\n",
       " 'originally': 227,\n",
       " 'served': 228,\n",
       " 'example': 229,\n",
       " 'considered': 230,\n",
       " 'produced': 231,\n",
       " 'used': 232,\n",
       " 'several': 233,\n",
       " 'central': 234,\n",
       " 'after': 235,\n",
       " 'century': 236}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2ind = make_word2ind(clips)\n",
    "print(f'{len(word2ind)} words from {len(clips)} clips')\n",
    "word2ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocabulary vocab.txt with 237 words.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[3.0206992e+06, 1.2088233e+07, 1.2249781e+07, ...,\n",
       "          2.9258790e+06, 4.1234288e+06, 5.0653525e+06],\n",
       "         [3.7445272e+06, 1.2955021e+07, 1.1109546e+07, ...,\n",
       "          6.1300660e+06, 4.0685995e+06, 4.4653445e+06],\n",
       "         [5.3232355e+06, 1.3308599e+07, 9.8624480e+06, ...,\n",
       "          1.1493683e+07, 6.8044315e+06, 6.9031365e+06],\n",
       "         ...,\n",
       "         [2.2587438e+08, 4.7370403e+08, 4.3282163e+08, ...,\n",
       "          4.4010202e+08, 4.4824752e+08, 4.9640749e+08],\n",
       "         [2.3184642e+08, 4.8583510e+08, 4.4488115e+08, ...,\n",
       "          4.5279341e+08, 4.5964202e+08, 5.1092733e+08],\n",
       "         [2.3024243e+08, 4.8226294e+08, 4.4219734e+08, ...,\n",
       "          4.5017613e+08, 4.5641414e+08, 5.0762787e+08]],\n",
       " \n",
       "        [[1.6670197e+07, 2.8485558e+07, 2.3342674e+07, ...,\n",
       "          2.0039564e+07, 1.5766136e+07, 3.5226504e+07],\n",
       "         [1.6401983e+07, 2.8842754e+07, 2.1929960e+07, ...,\n",
       "          1.9424996e+07, 1.7663596e+07, 3.5770996e+07],\n",
       "         [1.6426227e+07, 2.7336322e+07, 2.1926662e+07, ...,\n",
       "          1.8135546e+07, 1.7213010e+07, 3.7145504e+07],\n",
       "         ...,\n",
       "         [2.5416168e+08, 4.5315056e+08, 4.2160944e+08, ...,\n",
       "          4.5161379e+08, 4.4988630e+08, 4.8415754e+08],\n",
       "         [2.6128315e+08, 4.6610947e+08, 4.3025043e+08, ...,\n",
       "          4.6396573e+08, 4.6308544e+08, 4.9714374e+08],\n",
       "         [2.5973755e+08, 4.6294650e+08, 4.2793830e+08, ...,\n",
       "          4.6119808e+08, 4.6002893e+08, 4.9434525e+08]],\n",
       " \n",
       "        [[1.7689806e+07, 2.4864274e+07, 8.6373830e+06, ...,\n",
       "          4.1600484e+07, 2.7069866e+07, 3.5303560e+07],\n",
       "         [2.0789594e+07, 2.8565992e+07, 1.3377951e+07, ...,\n",
       "          4.0955564e+07, 2.5032306e+07, 3.9743576e+07],\n",
       "         [2.4421234e+07, 3.1233024e+07, 1.6348920e+07, ...,\n",
       "          3.5423912e+07, 2.5136918e+07, 4.6800840e+07],\n",
       "         ...,\n",
       "         [1.5392357e+08, 3.2029958e+08, 3.5393562e+08, ...,\n",
       "          3.6778614e+08, 3.4931523e+08, 3.7665795e+08],\n",
       "         [1.5799762e+08, 3.2968349e+08, 3.5981002e+08, ...,\n",
       "          3.7132576e+08, 3.5691990e+08, 3.8033114e+08],\n",
       "         [1.5786211e+08, 3.2870349e+08, 3.5679213e+08, ...,\n",
       "          3.6215149e+08, 3.5351706e+08, 3.7386259e+08]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.2776705e+07, 2.7787154e+07, 3.3558252e+07, ...,\n",
       "          1.6588723e+07, 1.2373884e+07, 2.7305076e+07],\n",
       "         [1.3858931e+07, 3.0633374e+07, 3.7210088e+07, ...,\n",
       "          1.8433658e+07, 1.4331973e+07, 2.9530490e+07],\n",
       "         [1.3697949e+07, 3.1591400e+07, 3.9310036e+07, ...,\n",
       "          2.0272900e+07, 1.6352990e+07, 2.9384394e+07],\n",
       "         ...,\n",
       "         [2.3242291e+08, 4.7093408e+08, 4.1669226e+08, ...,\n",
       "          4.3252608e+08, 4.2495024e+08, 5.1313213e+08],\n",
       "         [2.3943251e+08, 4.8431613e+08, 4.2611021e+08, ...,\n",
       "          4.4494534e+08, 4.3612992e+08, 5.2658179e+08],\n",
       "         [2.3768645e+08, 4.8160416e+08, 4.2433910e+08, ...,\n",
       "          4.4257738e+08, 4.3406250e+08, 5.2382326e+08]],\n",
       " \n",
       "        [[4.8602135e+06, 1.4412346e+07, 2.2661966e+07, ...,\n",
       "          1.6008596e+07, 2.2726588e+07, 1.4248922e+07],\n",
       "         [4.3623855e+06, 1.5697367e+07, 2.1783330e+07, ...,\n",
       "          1.7372586e+07, 2.3306948e+07, 1.4430292e+07],\n",
       "         [4.4593160e+06, 1.4585782e+07, 2.2515006e+07, ...,\n",
       "          1.8257396e+07, 2.3612368e+07, 1.3089607e+07],\n",
       "         ...,\n",
       "         [2.2676269e+08, 4.9245821e+08, 4.0867930e+08, ...,\n",
       "          4.2846752e+08, 4.4956819e+08, 5.2980285e+08],\n",
       "         [2.3182234e+08, 5.0128726e+08, 4.1730224e+08, ...,\n",
       "          4.3974269e+08, 4.6044637e+08, 5.4227725e+08],\n",
       "         [2.2934717e+08, 4.9658691e+08, 4.1389722e+08, ...,\n",
       "          4.3666435e+08, 4.5776614e+08, 5.3746061e+08]],\n",
       " \n",
       "        [[1.6354492e+07, 2.4580658e+07, 1.4757071e+07, ...,\n",
       "          1.6964636e+07, 2.5450518e+07, 3.6227252e+07],\n",
       "         [1.7276050e+07, 2.4581966e+07, 1.5517795e+07, ...,\n",
       "          1.4975109e+07, 2.5232802e+07, 3.8944376e+07],\n",
       "         [1.6925728e+07, 2.4318570e+07, 1.5335364e+07, ...,\n",
       "          1.2805575e+07, 2.5681736e+07, 3.8911572e+07],\n",
       "         ...,\n",
       "         [2.4324848e+08, 4.9096858e+08, 4.4818637e+08, ...,\n",
       "          4.2907962e+08, 4.7104112e+08, 4.9148106e+08],\n",
       "         [2.4650674e+08, 4.9988640e+08, 4.5819277e+08, ...,\n",
       "          4.3609331e+08, 4.8127718e+08, 5.0429475e+08],\n",
       "         [2.4429558e+08, 4.9482096e+08, 4.5412976e+08, ...,\n",
       "          4.3101606e+08, 4.7709530e+08, 5.0128384e+08]]], dtype=float32),\n",
       " array([154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
       "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
       "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
       "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
       "        154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154, 154,\n",
       "        154], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_cochleagrams(path: os.PathLike, word2ind: Dict[str, int]\n",
    "                      ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    data = []\n",
    "    targets = []\n",
    "    for f in os.listdir(path):\n",
    "        w = f.split('_')[0]\n",
    "        if not f.endswith(\".npy\") or w not in word2ind:\n",
    "            continue\n",
    "        x = np.load(os.path.join(path, f))\n",
    "        data.append(x)\n",
    "        targets.append(word2ind[w])\n",
    "    return np.array(data, dtype=np.float32), np.array(targets, dtype=np.int64)\n",
    "\n",
    "vocab = load_vocab()\n",
    "word2ind = vocab_word2ind(vocab)\n",
    "load_cochleagrams('parsed_files/babble', word2ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros([0,256,256])\n",
    "T = np.zeros([0])\n",
    "\n",
    "x, t = load_cochleagrams('parsed_files/babble', word2ind)\n",
    "X = np.append(X, x, axis=0)\n",
    "T = np.append(T, t, axis=0)\n",
    "x, t = load_cochleagrams('parsed_files/music', word2ind)\n",
    "X = np.append(X, x, axis=0)\n",
    "T = np.append(T, t, axis=0)\n",
    "x, t = load_cochleagrams('parsed_files/outdoor', word2ind)\n",
    "X = np.append(X, x, axis=0)\n",
    "T = np.append(T, t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13426, 256, 256), (13426,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, T, test_size=0.2,\n",
    "                                                    random_state=1234)\n",
    "\n",
    "os.makedirs('model_train/train', exist_ok=True)\n",
    "os.makedirs('model_train/test', exist_ok=True)\n",
    "\n",
    "np.save('model_train/train/inputs.npy', X_train)\n",
    "np.save('model_train/train/targets.npy', y_train)\n",
    "np.save('model_train/test/inputs.npy', X_test)\n",
    "np.save('model_train/test/targets.npy', y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
